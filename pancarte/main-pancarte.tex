\documentclass[25pt, a0paper,
               colspace=15mm, subcolspace=0mm,
               blockverticalspace=17mm]{tikzposter} % See Section 

\usepackage{graal-poster}
\usepackage{array}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{graphicx,caption}
\usepackage{float}
\usepackage{amsmath}
\usepackage{hyperref}

\setlength{\columnsep}{2cm}


\definecolor{PaleBlue}{rgb}{0,.55,.9}
\definecolor{PaleGreen}{rgb}{0,.7,.25}
\definecolor{RedPink}{rgb}{.9,0,.2}
\definecolor{Pink}{rgb}{.85,.35,.7}
\definecolor{Purple}{rgb}{.6,0,.75}
\definecolor{Orange}{rgb}{.9,.3,.05}

\colorlet{attentionColor}{Orange}
\colorlet{charEmbedColor}{RedPink}
\colorlet{predEmbedColor}{Pink}
% \colorlet{attentionColor}{GoldUL!90!black}
% \definecolor{attentionColor}{rgb}{.85,.5,.6}

\def\pathwidth{2pt}
\def\nodewidth{3pt}
\def\cornerCurvature{7pt}

\tikzstyle{embed}=[%
  draw,
  #1,
  % line width=3pt,
  anchor=north,
  minimum width=.8cm,
  minimum height=1.6cm,
  inner sep=0pt,
  text=#1!65!black,
  font=\fontsize{25pt}{24}\selectfont,
  ]




\title{\parbox{\linewidth}{\centering Semantic segmentation for mapping hockey \\ broadcast images in 2D plan}}
\institute{Department of Computer Science and Software Engineering, Université Laval}
\author{Philippe Blouin-Leclerc\up{\dag}, Stéphane Caron\hspace{5pt}\up{\dag}}

\begin{document}
\maketitle

\begin{columns}
\column{.4}
\block{Introduction}{%
We propose a novel way to recognize key locations within hockey broadcast images using semantic segmentation and convolutional neural networks (CNN). We implement a network that learn this semantic and could then be used for many applications such as mapping a broadcast image into a 2D plan.

\vspace{5mm}
\textbf{Motivations:}
\begin{itemize}
  \item Computer vision allows the detection of many events at the same time, which is well suited for sports analytics data collection.
  \item Semantic segmentation is often a key step as it brings a \textbf{general understanding} of the image.
\end{itemize}

\vspace{5mm}
\textbf{Related work:}
\begin{itemize}
  \item Homayounfar and al. (2017): Sports field localization via deep structured models.
  \item Ronneberger and al. (2015): Convolutional networks for biomedical image segmentation (U-Net).
\end{itemize}

\vspace{0mm}
\textbf{Goals:}
\begin{itemize}
  \item Evaluate the capability of CNN to learn the semantic representation of a hockey ring surface broadcast image.
  \item Provide meaningfull insights on how to build architectures that can learn well every components of an image.
  \item Propose a method that uses semantic segmentation representation to map objects and events into a 2D plan.
\end{itemize}

% \vspace{-15pt}

}



























\column{0.6}
\block{Semantic segmentation background}{

\vspace{0mm}
Semantic segmentation is a computer vision task where the model learns the general representation of an image by attributing a label to each and every pixels.

\vspace{5mm}
\textbf{Define the task:}
In order to make pixel-wise predictions, we need to have a representation saying which class is attached to each label. This representation is what we call a \textbf{mask} (see right-side image below).

\vspace{10mm}
{\centering \includegraphics[width=1.0\linewidth]{figures/task-representation.png}}

As many classification problems, we need to one-hot encode all labels (one matrix for each class) which mean we can summarize the dimensions workflow as follow for one 6 classes RBG image:

\vspace{-5mm}
\begin{gather*}
	(NbChannels, Height, Width) \Rightarrow (NbLabels, Height, Width) \Rightarrow (1, Height, Width) \\
	(3, 256, 451) \Rightarrow (6, 256, 451) \Rightarrow (1, 256, 451)
\end{gather*}


}	
\end{columns}











\begin{columns}

\column{.3}


% \block[bodyoffsety=48mm, titleoffsety=48mm]{Experiments}{
\block[bodyoffsety=0mm, titleoffsety=0mm]{Methodology}{
	
Our methodology is splitted in 3 main components:

\begin{enumerate}
	\item \textbf{Set up}
		\begin{itemize}
			\item Dataset creation
				\begin{itemize}
					\item 43 NHL broadcast images
				\end{itemize}
			\item Labeling task: \href{https://github.com/opencv/cvat}{cvat tool}
				\begin{itemize}
					\item 9 classes: crowd, ice, blue line, red line, goal line, circle zones, middle circle, dots and boards)
					\item 2 classes: crowd and ice
				\end{itemize}
		\end{itemize}
	\item \textbf{Semantic segmentation}
		\begin{itemize}
			\item Architecture set up
			\item Loss definition
			\item Data augmentation
			\item Training details
		\end{itemize}
	\item \textbf{Mapping to 2D plan}
		\begin{itemize}
			\item Key points recognition
			\item 2D translation
		\end{itemize}
\end{enumerate}


}


  \column{.7}
  \block[bodyoffsety=0mm, titleoffsety=0mm]{Architecture and training experiments}{
  	
  	\begin{multicols}{2}
  		\textbf{U-Net:} To perform our segmentation, we chose an architecture called U-Net. This network is \textbf{fast} and can be trained with \textbf{few images}. No pre-trained network found for that model.
  		
  		\vspace{10mm}
  		{\centering \includegraphics[width=1.0\linewidth]{figures/unet-architecture.png}}
  		
  		\textbf{VGG16:} We also decided to use a \textbf{pre-trained} VGG16 architecture without the max-pooling steps. The resuting output we'll then the \textbf{same size} as the input.
  		  		
  		\columnbreak
  		
  		\textbf{Loss definition:} We defined 2 kinds of loss:
  		\begin{itemize}
  			\item Cross-Entropy loss
  			\item Dice loss
  		\end{itemize}
  	
		The 9-classes problem is suffering from \textbf{class unbalance} (there is much more pixels of ice/crowd than lines or dots. We address that problem in the dataset labeling and in the loss definition. For Cross-Entropy loss, we adapted the weights for loss depending on the label frequency. We also implemeted the Dice loss:
		
		  \vspace{-15mm}
		\begin{gather*}
			\text{Dice Loss} = \frac{1}{nb\_class}*\sum\limits_{i=1}^{nb\_class}\Big(1-\frac{2\sum\limits_{pixels}y_{true}y_{pred}}{\sum\limits_{pixels}y_{true}^{2}+\sum\limits_{pixels}y_{pred}^{2}}\Big)
		\end{gather*}
  		
  		\textbf{Training details:}
  		
  	\end{multicols}
  
  
  }
  




\end{columns}




















\begin{columns}

  \column{.4}


  \block{Dataset}{

  We created our own dataset by making screenshots of NHL broadcast games and labeled them. Here is an example of the after the labeling task (for both 9 classes (left) and 2 classes (right)):
  
  \vspace{5mm}
  {\centering \includegraphics[width=30cm,height=8cm]{figures/example-labels.png}}
  
  To adress class imbalance, we draw larger areas around rare labels pixels such as dots, circles and lines.
  
  \vspace{1mm}
  
 Because we only had a total 43 images, we augmented our train dataset by making \textbf{horizontal rotation}. That kind of transformation makes sense in the context of a hockey ring (symmetry).
 
  \vspace{5mm}
 {\centering \includegraphics[width=30cm,height=8cm]{figures/rotation-example.png}}
 
   

  }









  \column{.4}
  \block{Results}
  {
  \begin{center}
  \setlength{\tabcolsep}{5mm}
  \begin{tabular}{c c c c c c}
  \toprule
  \multirow{2}{*}{\textbf{Task}} & \multirow{2}{*}{\textbf{Tag}} & \multirow{2}{*}{\textbf{Ex.}} & \multicolumn{3}{c}{\textbf{Ponderation}}\\
  \cline{4-6}
  \addlinespace[3mm]
  & & & Word & Left & Right\\
  \midrule
  \multirow{9}{*}{NER} & O           & 1039  & \colorbold{0.81}    & 0.08    & 0.11 \\
  & B-PERS      & 63    & 0.21    & 0.31    & \colorbold{0.49} \\
  & I-PER     & 119   & 0.16  & \colorbold{0.52} & 0.32 \\
  & B-ORG     & 40  & 0.26  & 0.30  & \colorbold{0.44} \\ 
  & I-ORG     & 3     & 0.27  & 0.31      & \colorbold{0.42} \\
  & B-LOC     & 13  & 0.23      & 0.30  & \colorbold{0.47} \\
  & I-LOC     & 2     & 0.16  & \colorbold{0.48} & 0.36 \\
  & B-MISC      & 47  & \colorbold{0.40} & 0.21  & 0.39 \\
  & I-MISC      & 5     & \colorbold{0.41} & 0.26  & 0.33 \\
  \midrule
  \multirow{5}{*}{POS} & NNP  & 308 & 0.29  & 0.31  & \colorbold{0.40} \\
  & NN  & 46  & \colorbold{0.45} & 0.20  & 0.35 \\
  & CD  & 827 & \colorbold{0.86} & 0.05  & 0.09 \\
  & NNS & 23  & \colorbold{0.37} & 0.24  & \colorbold{0.39} \\
  & JJ  & 100 & \colorbold{0.49} & 0.15  & 0.36 \\
  \bottomrule
  \end{tabular}
  \end{center}
  
  \vspace{1.5mm}
   Average weights assigned to word's characters, left context and right context by the attention mechanism. We can clearly see the shift of attention according to the target entity. We also observe that the attention depends on the task at hand.
  \vspace{-3mm}
  }







  
  
  
  \column{.2}
  
%
%  \block{Performance gain}{%
%  \begin{center}
%  \setlength{\tabcolsep}{5mm}
%  \begin{tabular}{c c c c c}
%  \toprule
%  \textbf{Task} & \textbf{Metric} & \textbf{Random Emb.} & \textbf{Our module} & \textbf{Gain}\\
%  \midrule
%  NER      & F1   & 77.56 & \colorbold{80.62} & 3.9\% \\
%  POS      & acc. & 91.41 & \colorbold{92.58} & 1.2\% \\
%  % Chunking & acc. & 92.63 & 93.16  & \textbf{93.19} \\
%  % Keyphrase& F1   & 37.40 & 39.56 & \textbf{39.77} \\
%  \bottomrule
%  \end{tabular}
%  \end{center}
%  
%  \vspace{2.5mm}
%  The impact of our model on two NLP downstream tasks. We compare our OOV embeddings prediction scheme against random embeddings.
%  \vspace{-12mm}
%  }


  
  
  
  
  
  
  
  
  
  
  
  
  \block{Conclusion}{
  
  \textbf{Discussion:}
    \begin{itemize}
        \item For 9-classes predictions, 
        \item \colorbold{The attention mechanism works}: depending on the task, the network will use either more the context or the morphology to generate an embedding.
    \end{itemize}
    
    \textbf{Future works:}
    \begin{itemize}
        \item Extract and label \textbf{more images} (was time consuming)
        \item Starts from a pre-trained model as our encoder and build a \textbf{proper decoder} for this specific task.
        \item Use the semantic segmentation learned by the model to map key areas on the ice into a \text{2D plan}.
    \end{itemize}
    \vspace{-3.5mm}
  }
\end{columns}

\end{document}